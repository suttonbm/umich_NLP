{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START_SYMBOL = '*/*'\n",
    "STOP_SYMBOL = 'STOP/STOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fancySplit(sents):\n",
    "    result = [[START_SYMBOL, START_SYMBOL] + s.split() + [STOP_SYMBOL] \\\n",
    "                    for s in sents]\n",
    "    result = [[tok for word in sent for tok in word.rsplit('/',1)] \\\n",
    "                    for sent in result]\n",
    "    return result\n",
    "\n",
    "def split_wordtags(brown_train):\n",
    "    toks = fancySplit(brown_train)\n",
    "    brown_words = [sent[0::2] for sent in toks]\n",
    "    brown_tags = [sent[1::2] for sent in toks]\n",
    "    return brown_words, brown_tags\n",
    "\n",
    "def getCounts(toks):\n",
    "    d = defaultdict(int)\n",
    "    for t in toks:\n",
    "        d[t] += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/brown_tagged_xample.txt', 'r') as ifile:\n",
    "    corpus = ifile.readlines()\n",
    "\n",
    "(words, tags) = split_wordtags(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_known(brown_words):\n",
    "    flatWords = [w for sublist in brown_words for w in sublist]\n",
    "    wordCounts = getCounts(flatWords)\n",
    "    \n",
    "    known_words = set([k for k, v in wordCounts.iteritems() if v > 5])\n",
    "    return known_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "known = calc_known(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'all', 'on', 'have', 'Island']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(known)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RARE_SYMBOL = '_RARE_'\n",
    "def replace_rare(brown_words, known_words):\n",
    "    brown_words_rare = [[s if s in known_words else RARE_SYMBOL for s in sent] \\\n",
    "                            for sent in brown_words]\n",
    "    return brown_words_rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filteredWords = replace_rare(words, known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*',\n",
       " '*',\n",
       " '_RARE_',\n",
       " 'that',\n",
       " 'time',\n",
       " '_RARE_',\n",
       " '_RARE_',\n",
       " '_RARE_',\n",
       " '_RARE_',\n",
       " 'and',\n",
       " '_RARE_',\n",
       " '_RARE_',\n",
       " 'to',\n",
       " '_RARE_',\n",
       " 'their',\n",
       " '_RARE_',\n",
       " '.',\n",
       " 'STOP']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredWords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open Brown development data (question 5)\n",
    "infile = open(\"data/Brown_dev.txt\", \"r\")\n",
    "brown_dev = infile.readlines()\n",
    "infile.close()\n",
    "\n",
    "# format Brown development data here\n",
    "brown_dev_words = []\n",
    "for sentence in brown_dev:\n",
    "    brown_dev_words.append(sentence.split(\" \")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'had',\n",
       " 'obtained',\n",
       " 'and',\n",
       " 'provisioned',\n",
       " 'a',\n",
       " 'veteran',\n",
       " 'ship',\n",
       " 'called',\n",
       " 'the',\n",
       " 'Discovery',\n",
       " 'and',\n",
       " 'had',\n",
       " 'recruited',\n",
       " 'a',\n",
       " 'crew',\n",
       " 'of',\n",
       " 'twenty-one',\n",
       " ',',\n",
       " 'the',\n",
       " 'largest',\n",
       " 'he',\n",
       " 'had',\n",
       " 'ever',\n",
       " 'commanded',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_dev_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "import math\n",
    "\n",
    "def calc_emission(brown_words_rare, brown_tags):\n",
    "    words = [w for sublist in brown_words_rare for w in sublist]\n",
    "    tags = [t for sublist in brown_tags for t in sublist]\n",
    "\n",
    "    tag_counts = getCounts(tags)\n",
    "    taglist = set(tag_counts.keys())\n",
    "\n",
    "    e_values = {}\n",
    "    for tag in taglist:\n",
    "        mask = [1 if t==tag else 0 for t in tags]\n",
    "        words_masked = compress(words, mask)\n",
    "        wordCount = getCounts(words_masked)\n",
    "        tagCount = float(tag_counts[tag])\n",
    "\n",
    "        for word in wordCount.keys():\n",
    "            e_values[(word, tag)] = math.log(wordCount[word]/tagCount, 2)\n",
    "\n",
    "    return e_values, taglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_values, taglist = calc_emission(filteredWords, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADV',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'PRT',\n",
       " 'DET',\n",
       " '*',\n",
       " 'STOP',\n",
       " '.',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'NUM',\n",
       " 'CONJ',\n",
       " 'ADJ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
