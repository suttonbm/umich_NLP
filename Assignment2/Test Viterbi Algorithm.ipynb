{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import compress\n",
    "import numpy as np\n",
    "\n",
    "START_SYMBOL = '*/*'\n",
    "STOP_SYMBOL = 'STOP/STOP'\n",
    "RARE_SYMBOL = '_RARE_'\n",
    "RARE_WORD_MAX_FREQ = 5\n",
    "LOG_PROB_OF_ZERO = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SparseMatrix:\n",
    "    def __init__(self):\n",
    "        self.elements = {}\n",
    "\n",
    "    def add(self, tuple, value):\n",
    "        self.elements[tuple] = value\n",
    "\n",
    "    def get(self, tuple):\n",
    "        try:\n",
    "            return self.elements[tuple]\n",
    "        except KeyError:\n",
    "            return LOG_PROB_OF_ZERO\n",
    "\n",
    "# This function takes data to tag (brown_dev_words), a set of all possible tags (taglist), a set of all known words (known_words),\n",
    "# trigram probabilities (q_values) and emission probabilities (e_values) and outputs a list where every element is a tagged sentence\n",
    "# (in the WORD/TAG format, separated by spaces and with a newline in the end, just like our input tagged data)\n",
    "# brown_dev_words is a python list where every element is a python list of the words of a particular sentence.\n",
    "# taglist is a set of all possible tags\n",
    "# known_words is a set of all known words\n",
    "# q_values is from the return of calc_trigrams()\n",
    "# e_values is from the return of calc_emissions()\n",
    "# The return value is a list of tagged sentences in the format \"WORD/TAG\", separated by spaces. Each sentence is a string with a\n",
    "# terminal newline, not a list of tokens. Remember also that the output should not contain the \"_RARE_\" symbol, but rather the\n",
    "# original words of the sentence!\n",
    "def viterbi(brown_dev_words, taglist, known_words, q_values, e_values, debug=True):\n",
    "    # Create a list of tags for easy indexing.\n",
    "    tags = list(taglist)\n",
    "    words = list(set([k[0] for k in e_values.keys()]))\n",
    "\n",
    "    # Convert q_values and e_values into sparse matrices\n",
    "    # This enables easy indexing to get probabilities:\n",
    "    #\n",
    "    # P(word | preposition) = e_mat[w, p]\n",
    "    # P(p3 | p1 p2) = q_mat[p1, p2, p3]\n",
    "    #\n",
    "    # This also simplifies and speeds up computation in the recursion phase\n",
    "    # because tuples do not need to be created dynamically to calculate\n",
    "    # the probabilities of each item.\n",
    "    nTags = len(tags)\n",
    "    tag_Dict = {k: v for k, v in zip(tags, range(nTags))}\n",
    "    tag_ReverseDict = {v: k for k, v in tag_Dict.iteritems()}\n",
    "    START_ID = tag_Dict['*']\n",
    "    STOP_ID = tag_Dict['STOP']\n",
    "    nWords = len(words)\n",
    "    word_Dict = {k: v for k, v in zip(words, range(nWords))}\n",
    "    \n",
    "    if (debug):\n",
    "        print tag_Dict\n",
    "        print word_Dict\n",
    "\n",
    "    e_mat = SparseMatrix()\n",
    "    for t, p in e_values.iteritems():\n",
    "        w_id = word_Dict[t[0]]\n",
    "        t_id = tag_Dict[t[1]]\n",
    "        e_mat.add((w_id, t_id), p)\n",
    "    # END for\n",
    "    q_mat = SparseMatrix()\n",
    "    for t, p in q_values.iteritems():\n",
    "        t1_id = tag_Dict[t[0]]\n",
    "        t2_id = tag_Dict[t[1]]\n",
    "        t3_id = tag_Dict[t[2]]\n",
    "        q_mat.add((t1_id, t2_id, t3_id), p)\n",
    "    # END for\n",
    "\n",
    "    def recurseViterbi(j, n, wordN_id, vMatrix, bMatrix, bOverride = None):\n",
    "        # Need to have the option to override the backpointed matrix for the\n",
    "        # second column, where no data has been initialized.\n",
    "        if bOverride is None:\n",
    "            q_Probs = [q_mat.get((bMatrix[i, n-2], i, j)) for i in range(nTags)]\n",
    "        else:\n",
    "            q_Probs = [q_mat.get((bOverride, i, j)) for i in range(nTags)]\n",
    "        # END if\n",
    "\n",
    "        # Word emission probability is constant across all items\n",
    "        e_Prob = e_mat.get((wordN_id, j))\n",
    "\n",
    "        # Note that we are working with log probabilities, so we can sum\n",
    "        # for the intersetion of probabilities.\n",
    "        return np.add(np.add(q_Probs, vMatrix[:, n-1]), e_Prob)\n",
    "    # END recurseViterbi\n",
    "\n",
    "    def myViterbi(sent):\n",
    "        # Initialize a matrix with N rows and M columns, where:\n",
    "        #   N = number of POS Tag Classes\n",
    "        #   M = number of words in the sentence\n",
    "        print \"Initializing Viterbi and Backtrace Matrices\"\n",
    "        vMat = np.zeros((nTags, len(sent)), np.dtype(np.float))\n",
    "        bMat = np.zeros((nTags, len(sent)-1), np.dtype(np.int))\n",
    "\n",
    "        # Initizlization step for initial transition probabilities.\n",
    "        # use first word in the sentence unless it is rare.\n",
    "        word0 = word_Dict[sent[0] if sent[0] in known_words else RARE_SYMBOL]\n",
    "        for j in range(nTags):\n",
    "            # Set the initial transition probabilities.\n",
    "            vMat[j, 0] = q_mat.get((START_ID, START_ID, j)) + \\\n",
    "                            e_mat.get((word0, j))\n",
    "\n",
    "            # Note: the backtrace is not used for the first column in this\n",
    "            #       implementation because the starting tag is known (*).\n",
    "        # END for\n",
    "        if debug:\n",
    "            print \"Set initial transition probabilities.\"\n",
    "            print vMat\n",
    "\n",
    "        # Initialization step for the second column of transition probabilities\n",
    "        # Hard-coded due to trigram model\n",
    "        word1 = word_Dict[sent[1] if sent[1] in known_words else RARE_SYMBOL]\n",
    "        for j in range(nTags):\n",
    "            # Transition probabilities for the second column are recursively\n",
    "            # defined based on the first column.\n",
    "            vProbs = recurseViterbi(j, 1, word1, vMat, bMat, START_ID)\n",
    "            vMat[j, 1] = np.max(vProbs)\n",
    "            bMat[j, 0] = np.argmax(vProbs)\n",
    "        # END for\n",
    "        if debug:\n",
    "            print \"Set second column with recursive definition\"\n",
    "            print vMat\n",
    "            print bMat\n",
    "\n",
    "        # Recursion phase\n",
    "        for n in range(2, len(sent)):\n",
    "            # Use selected word unless it is a rare word.\n",
    "            wordN = word_Dict[sent[n] if sent[n] in known_words else RARE_SYMBOL]\n",
    "            for j in range(nTags):\n",
    "                vProbs = recurseViterbi(j, n, wordN, vMat, bMat)\n",
    "                vMat[j, n] = np.max(vProbs)\n",
    "                bMat[j, n-1] = np.argmax(vProbs)\n",
    "            # END for\n",
    "            if debug:\n",
    "                print \"Set column {0} recursively\".format(n)\n",
    "                print vMat\n",
    "                print bMat\n",
    "        # END for\n",
    "\n",
    "        # Terminate the recursion\n",
    "        vProbs = recurseViterbi(STOP_ID, len(sent), STOP_ID, vMat, bMat)\n",
    "        p_star = np.max(vProbs)\n",
    "        q_star = np.argmax(vProbs)\n",
    "        \n",
    "        if debug:\n",
    "            print \"P*: {0}\".format(p_star)\n",
    "            print \"Q*: {0}\".format(q_star)\n",
    "\n",
    "        # Iterate through the backtrace pointer\n",
    "        ptr = q_star\n",
    "        tagIds = []\n",
    "        for k in range(len(sent)-2, -1, -1):\n",
    "            tagIds.insert(0, ptr)\n",
    "            ptr = bMat[ptr, k]\n",
    "            if debug:\n",
    "                print \"Info for word {0}\".format(k+1)\n",
    "                print tagIds\n",
    "                print ptr\n",
    "        # END for\n",
    "        tagIds.insert(0, ptr)\n",
    "\n",
    "        # Get back the tags\n",
    "        tags = [tag_ReverseDict[int(k)] for k in tagIds]\n",
    "\n",
    "        return ' '.join(['/'.join((sent[i],tags[i])) for i in range(len(sent))])\n",
    "    # END myViterbi\n",
    "\n",
    "    tagged = [myViterbi(sent) for sent in brown_dev_words]\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'C': 1, 'B': 2, '*': 3, 'STOP': 4, '.': 5}\n",
      "{'watch': 0, 'is': 1, 'STOP': 2, '.': 3, 'to': 4, 'fun': 5, 'He': 6}\n",
      "Initializing Viterbi and Backtrace Matrices\n",
      "Set initial transition probabilities.\n",
      "[[   -2.     0.     0.     0.     0.     0.]\n",
      " [-1004.     0.     0.     0.     0.     0.]\n",
      " [  -66.     0.     0.     0.     0.     0.]\n",
      " [-2000.     0.     0.     0.     0.     0.]\n",
      " [-2000.     0.     0.     0.     0.     0.]\n",
      " [-2000.     0.     0.     0.     0.     0.]]\n",
      "Set second column with recursive definition\n",
      "[[   -2. -1004.     0.     0.     0.     0.]\n",
      " [-1004. -1130.     0.     0.     0.     0.]\n",
      " [  -66.    -4.     0.     0.     0.     0.]\n",
      " [-2000. -2002.     0.     0.     0.     0.]\n",
      " [-2000. -2002.     0.     0.     0.     0.]\n",
      " [-2000. -2002.     0.     0.     0.     0.]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "Set column 2 recursively\n",
      "[[   -2. -1004.    -6.     0.     0.     0.]\n",
      " [-1004. -1130. -1006.     0.     0.     0.]\n",
      " [  -66.    -4. -1008.     0.     0.     0.]\n",
      " [-2000. -2002. -2004.     0.     0.     0.]\n",
      " [-2000. -2002. -2004.     0.     0.     0.]\n",
      " [-2000. -2002. -1020.     0.     0.     0.]]\n",
      "[[0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]]\n",
      "Set column 3 recursively\n",
      "[[   -2. -1004.    -6. -1010.     0.     0.]\n",
      " [-1004. -1130. -1006.    -8.     0.     0.]\n",
      " [  -66.    -4. -1008. -2006.     0.     0.]\n",
      " [-2000. -2002. -2004. -2006.     0.     0.]\n",
      " [-2000. -2002. -2004. -2006.     0.     0.]\n",
      " [-2000. -2002. -1020. -2006.     0.     0.]]\n",
      "[[0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]]\n",
      "Set column 4 recursively\n",
      "[[   -2. -1004.    -6. -1010. -1016.     0.]\n",
      " [-1004. -1130. -1006.    -8. -1016.     0.]\n",
      " [  -66.    -4. -1008. -2006.   -10.     0.]\n",
      " [-2000. -2002. -2004. -2006. -2008.     0.]\n",
      " [-2000. -2002. -2004. -2006. -2008.     0.]\n",
      " [-2000. -2002. -1020. -2006. -1040.     0.]]\n",
      "[[0 2 0 1 0]\n",
      " [0 2 0 1 0]\n",
      " [0 2 0 1 0]\n",
      " [0 2 0 1 0]\n",
      " [0 2 0 1 0]\n",
      " [0 2 0 1 0]]\n",
      "Set column 5 recursively\n",
      "[[   -2. -1004.    -6. -1010. -1016. -2010.]\n",
      " [-1004. -1130. -1006.    -8. -1016. -2010.]\n",
      " [  -66.    -4. -1008. -2006.   -10. -2010.]\n",
      " [-2000. -2002. -2004. -2006. -2008. -2010.]\n",
      " [-2000. -2002. -2004. -2006. -2008. -2010.]\n",
      " [-2000. -2002. -1020. -2006. -1040.   -10.]]\n",
      "[[0 2 0 1 2]\n",
      " [0 2 0 1 2]\n",
      " [0 2 0 1 2]\n",
      " [0 2 0 1 2]\n",
      " [0 2 0 1 2]\n",
      " [0 2 0 1 2]]\n",
      "P*: -1009.0\n",
      "Q*: 5\n",
      "Info for word 5\n",
      "[5]\n",
      "2\n",
      "Info for word 4\n",
      "[2, 5]\n",
      "1\n",
      "Info for word 3\n",
      "[1, 2, 5]\n",
      "0\n",
      "Info for word 2\n",
      "[0, 1, 2, 5]\n",
      "2\n",
      "Info for word 1\n",
      "[2, 0, 1, 2, 5]\n",
      "0\n",
      "['He/A is/B fun/A to/C watch/B ./.']\n"
     ]
    }
   ],
   "source": [
    "def testViterbi1():\n",
    "    taglist = set(['*','A','B','C','.','STOP'])\n",
    "    known_words = set(['He', 'is', 'fun', 'to', 'watch', '.', 'STOP', '*', '_RARE_'])\n",
    "    sent = [['He', 'is', 'fun', 'to', 'watch', '.']]\n",
    "    q_vals = { \\\n",
    "             ('*','*','A'): -1., \\\n",
    "             ('*','*','B'): -64., \\\n",
    "             ('*','A','B'): -1., \\\n",
    "             ('*','A','C'): -128., \\\n",
    "             ('A','B','A'): -1., \\\n",
    "             ('A','B','C'): -2., \\\n",
    "             ('B','A','C'): -1., \\\n",
    "             ('A','C','B'): -1., \\\n",
    "             ('C','B','.'): -1., \\\n",
    "             ('B','.','STOP'): 1., \\\n",
    "             ('A','B','C'): -2., \\\n",
    "             ('B','A','A'): -4., \\\n",
    "             ('A','C','C'): -8., \\\n",
    "             ('A','B','.'): -16., \\\n",
    "             ('A','C','.'): -32., \\\n",
    "             ('B','*','*'): -64.}\n",
    "    e_vals = { \\\n",
    "             ('He','A'): -1., \\\n",
    "             ('He','B'): -2., \\\n",
    "             ('is','B'): -1., \\\n",
    "             ('is','A'): -2., \\\n",
    "             ('fun','A'): -1., \\\n",
    "             ('to','C'): -1., \\\n",
    "             ('watch','B'): -1., \\\n",
    "             ('.','.'): 1., \\\n",
    "             ('STOP','STOP'): 1., \\\n",
    "             ('He','C'): -4., \\\n",
    "             ('fun','B'): -4., \\\n",
    "             ('watch','A'): -8.}\n",
    "    \n",
    "    result = viterbi(sent, taglist, known_words, q_vals, e_vals)\n",
    "    print result\n",
    "# END\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "testViterbi1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
