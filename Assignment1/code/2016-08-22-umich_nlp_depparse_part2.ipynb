{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the Operations\n",
    "First, let's discuss implementation of the four supported operations of our shift-reduce parser.  As discussed in [part 1]({{ base.url }}/2016/08/umich_nlp_depparse_intro/), the four supported operations are `left_arc()`, `right_arc()`, `shift()`, and `reduce()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left Arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def left_arc(conf, relation):\n",
    "    if not conf.buffer:\n",
    "        return -1\n",
    "\n",
    "    if conf.stack[-1] == 0:\n",
    "        return -1\n",
    "\n",
    "    for arc in conf.arcs:\n",
    "        if conf.stack[-1] == arc[2]:\n",
    "            return -1\n",
    "\n",
    "    b = conf.buffer[0]\n",
    "    s = conf.stack.pop(-1)\n",
    "    # Add the arc (b, L, s)\n",
    "    conf.arcs.append((b, relation, s))\n",
    "    pass\n",
    "# END left_arc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Right Arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def right_arc(conf, relation):\n",
    "    if not conf.buffer or not conf.stack:\n",
    "        return -1\n",
    "\n",
    "    s = conf.stack[-1]\n",
    "    b = conf.buffer.pop(0)\n",
    "\n",
    "    conf.stack.append(b)\n",
    "    conf.arcs.append((s, relation, b))\n",
    "    pass\n",
    "# END right_arc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce(conf):\n",
    "    if not conf.stack:\n",
    "        return -1\n",
    "\n",
    "    for arc in conf.arcs:\n",
    "        if conf.stack[-1] == arc[2]:\n",
    "            s = conf.stack.pop(-1)\n",
    "            return\n",
    "    return -1\n",
    "# END reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift(conf):\n",
    "    if not conf.buffer or not conf.stack:\n",
    "        return -1\n",
    "\n",
    "    b = conf.buffer.pop(0)\n",
    "    conf.stack.append(b)\n",
    "    pass\n",
    "# END shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As might be expected, the implementation of the functions is straightforward.  No explanation of the logic is given, but I think the reader should be able to interpret fairly easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of Features\n",
    "The four functions of the shift-reduce parser above define the actions that are available for a given configuration, but we need a brain to tell the program when to apply which function.  As discussed in part 1, we could try to create some hard-coded rules based on various configurations.  However, with this approach, the program would be inflexible and likely perform poorly.  Instead, we can use supervised machine learning to have the program learn for itself how to apply the shift-reduce functions.\n",
    "\n",
    "As with any supervised learning problem, we need two things - a set of golden data to train the machine, and a method of extracting useful features from that golden data.  For this problem, we were provided golden data in the form of CONLL datasets for english, danish, and swedish.  This dataset essentially provides a series of configurations accompanied by the correct operation and label (if applicable).  Our assignment was to extract \"features\" from each configuration - properties about the configuration which provide positive predictive value for the operation to be used.\n",
    "\n",
    "I made multiple iterations to converge to a solution; these are outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Structures\n",
    "Before getting into the iterations on the feature extractor, let's first define the data structure that is used the the extractor.  As discussed previously, there are three components of a parser configuration.  $B$ is the buffer, remaining words to be parsed.  $\\Sigma$ is the stack, holding words that have been processed via the `right_arc()` or `shift()` operations.  $A$ is the set of arcs that have been added to the dependency graph.\n",
    "\n",
    "Note that $B$ and $\\Sigma$ both contain words, which may have a variety of properties.  Therefore it may make sense to index those words and store them in a separate data structure.  Let's call that $T$, a list of dictionaries storing the properties of each word.\n",
    "\n",
    "Let's take a look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from providedcode import dataset\n",
    "data = dataset.get_english_train_corpus().parsed_sents()\n",
    "smalldata = random.sample(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a partially completed configuration to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from providedcode.transitionparser import Configuration\n",
    "\n",
    "def getDepRelation(parent, child, graph):\n",
    "    p_node = graph.nodes[parent]\n",
    "    c_node = graph.nodes[child]\n",
    "    \n",
    "    if c_node['word'] is None:\n",
    "        return None\n",
    "    if c_node['head'] == p_node['address']:\n",
    "        return c_node['rel']\n",
    "    else:\n",
    "        return None\n",
    "    pass\n",
    "\n",
    "testGraph = smalldata[0]\n",
    "conf = Configuration(testGraph, None)\n",
    "for k in range(11):\n",
    "    b0 = conf.buffer[0]\n",
    "    if conf.stack:\n",
    "        s0 = conf.stack[-1]\n",
    "        \n",
    "        # Look for left-arc relationship\n",
    "        rel = getDepRelation(b0, s0, testGraph)\n",
    "        if rel is not None:\n",
    "            left_arc(conf, rel)\n",
    "            continue\n",
    "        \n",
    "        # Look for right-arc relationship\n",
    "        rel = getDepRelation(s0, b0, testGraph)\n",
    "        if rel is not None:\n",
    "            right_arc(conf, rel)\n",
    "            continue\n",
    "        \n",
    "        # Look for reduce\n",
    "        flag = False\n",
    "        for k in range(s0):\n",
    "            if getDepRelation(k, b0, testGraph) is not None:\n",
    "                flag = True\n",
    "            if getDepRelation(b0, k, testGraph) is not None:\n",
    "                flag = True\n",
    "        if flag:\n",
    "            reduce(conf)\n",
    "            continue\n",
    "    \n",
    "    # By default, apply shift\n",
    "    shift(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the above code is left as an exercise to the reader.  Essentially, we've taken a single sentence from the golden source and applied the first ten operations to it in order.  We should be left with a partially completed configuration for further inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's inspect the stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct way to interpret the stack is to see the leftmost element as the bottom and the rightmost element as the top.  We can see that the current configuration of the stack has two items.  The first is word '6', and the last is the root element, '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buffer is interpreted in the opposite way.  The leftmost element is the \"next\" item in the buffer, and the rightmost element is the \"last\" item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'adpmod', 2),\n",
       " (4, u'det', 3),\n",
       " (2, u'adpobj', 4),\n",
       " (6, u'auxpass', 5),\n",
       " (6, u'csubjpass', 1),\n",
       " (0, u'ROOT', 6)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, six dependency relations have now been added to the dependency map.  For example, '3' depends on '4', and the relationship is 'det', or determiner.\n",
    "\n",
    "Let's confirm this by looking at the words themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "father\n"
     ]
    }
   ],
   "source": [
    "print testGraph.nodes[3]['word']\n",
    "print testGraph.nodes[4]['word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the dependency relation specified above makes sense.  \"the\" depends on \"father\" because it is the determiner for \"father\".  We could replace \"the\" with \"a\" and have the same result!\n",
    "\n",
    "Finally, there are many different properties stored for the words.  Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ctag',\n",
       " u'head',\n",
       " u'word',\n",
       " u'rel',\n",
       " u'lemma',\n",
       " u'tag',\n",
       " u'deps',\n",
       " u'address',\n",
       " u'feats']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testGraph.nodes[3].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of these properties are useful for training our SVM.  The descriptions of useful properties are as follows:\n",
    "  * 'ctag': Coarse-grained part of speech.  For example, \"NOUN\"\n",
    "  * 'tag': Fine-grained part of speech. For example, \"NNS\", or singular noun\n",
    "  * 'word': The word itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see how the data is being stored, let's take a look at the task of feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration #1 - POS Tags Unigram Model\n",
    "The first iteration of the feature extractor only made use of the coarse-grained part of speech for the top word in the stack and the buffer.  For example, $S=['company',...]$ and $\\Sigma=['was',...]$ might identify two features.  \"Company\" would be a \"NOUN\" and \"was\" would be a \"VERB\".\n",
    "\n",
    "In code, this might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STK_0_TAG_VERB'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = conf.stack[-1]\n",
    "tok = testGraph.nodes[s]\n",
    "\"STK_0_CTAG_{0}\".format(tok['ctag'].upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only this feature, the SVM was able to achieve ~47% accuracy.  Changing to the fine-grained part of speech improved accuracy to ~53%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration #2 - Parents / Children in Queue\n",
    "The second iteration looks at whether there is an arc already created where the target word is a parent or a child.  In addition, if a dependency relation exists, the label for that relation is noted.  The target is limited to the top word in the stack or the buffer.\n",
    "\n",
    "The implementation is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNDeps(n, arcs):\n",
    "    parents = 0\n",
    "    children = 0\n",
    "\n",
    "    for arc in arcs:\n",
    "        if arc[0] == n:\n",
    "            children += 1\n",
    "        # END if\n",
    "        if arc[2] == n:\n",
    "            parents += 1\n",
    "    # END for\n",
    "\n",
    "    return (parents, children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then features are extracted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STK_0_PARENTS_True\n",
      "STK_0_CHILDREN_True\n"
     ]
    }
   ],
   "source": [
    "(parents, children) = getNDeps(s, conf.arcs)\n",
    "print \"STK_0_PARENTS_{0}\".format(parents>0)\n",
    "print \"STK_0_CHILDREN_{0}\".format(children>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this feature to the data improved accuracy to ~60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration #3 - N-Gram POS Model\n",
    "In the third (and final) iteration, the part of speech extraction was upgraded from a unigram to a trigram model.  Rather than looking only at the top word in the stack and buffer, the part of speech was extracted from the next two items in each as well.\n",
    "\n",
    "Features extracted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STK_1_TAG_VBN\n",
      "STK_2_NULL\n"
     ]
    }
   ],
   "source": [
    "if len(conf.stack) >= 2:\n",
    "    next_s = conf.stack[1]\n",
    "    next_Tok = testGraph.nodes[next_s]\n",
    "    if next_s == 0:\n",
    "        print \"STK_1_ROOT\"\n",
    "    else:\n",
    "        print \"STK_1_TAG_{0}\".format(next_Tok['tag'].upper())\n",
    "else:\n",
    "    print \"STK_1_NULL\"\n",
    "if len(conf.stack) >= 3:\n",
    "    later_s = conf.stack[2]\n",
    "    next_Tok = testGraph.nodes[later_s]\n",
    "    if later_s == 0:\n",
    "        print \"STK_2_ROOT\"\n",
    "    else:\n",
    "        print \"STK_2_TAG_{0}\".format(next_Tok['tag'].upper())\n",
    "else:\n",
    "    print \"STK_2_NULL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this final feature extraction method, ~67% accuracy was achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
